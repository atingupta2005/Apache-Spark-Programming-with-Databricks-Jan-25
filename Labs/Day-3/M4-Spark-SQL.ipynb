{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c02985",
   "metadata": {},
   "source": [
    "**Module 4: Spark SQL**\n",
    "\n",
    "### SQL in Spark: Overview and Usage\n",
    "\n",
    "Spark SQL is a module in Apache Spark that provides a structured data processing interface using SQL-like queries. It bridges the gap between the relational and procedural paradigms, allowing data analysts and developers to interact with data using SQL while leveraging Spark's scalability and performance.\n",
    "\n",
    "**Key Features of Spark SQL:**\n",
    "- **Unified Data Access**: Access data from various sources like JSON, Parquet, Avro, Hive, and JDBC.\n",
    "- **Schema-Based Processing**: Enables schema definition and enforcement for structured data.\n",
    "- **Integration with DataFrames**: Allows seamless transitions between SQL queries and DataFrame APIs.\n",
    "- **Optimized Query Execution**: Uses the Catalyst Optimizer for efficient query planning.\n",
    "\n",
    "*Example 1: Running SQL queries on a DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from JSON\n",
    "flight_data_json = \"dbfs:/mnt/data/data/flight-data/json/2015-summary.json\"\n",
    "df = spark.read.format(\"json\").load(flight_data_json)\n",
    "\n",
    "# Register DataFrame as a SQL table\n",
    "df.createOrReplaceTempView(\"flight_data\")\n",
    "\n",
    "# Query using Spark SQL\n",
    "query = \"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, SUM(count) AS total_flights \n",
    "FROM flight_data \n",
    "GROUP BY DEST_COUNTRY_NAME \n",
    "ORDER BY total_flights DESC \n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "sql_result = spark.sql(query)\n",
    "sql_result.show()\n",
    "\n",
    "# Additional data transformations\n",
    "df_filtered = df.filter(df.count > 500)\n",
    "df_grouped = df_filtered.groupBy(\"DEST_COUNTRY_NAME\").agg({'count': 'sum'})\n",
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce030b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Creating and Managing Tables with Spark SQL\n",
    "\n",
    "Spark SQL allows users to create and manage tables, supporting both temporary and permanent tables.\n",
    "\n",
    "**1. Temporary Views:**\n",
    "Temporary views exist only within the Spark session and are not persistent.\n",
    "\n",
    "*Example 2: Creating and querying a temporary view*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a temporary view\n",
    "df.createOrReplaceTempView(\"temp_flights\")\n",
    "\n",
    "# Querying the temporary view\n",
    "query = \"\"\"\n",
    "SELECT ORIGIN_COUNTRY_NAME, COUNT(*) AS num_flights\n",
    "FROM temp_flights\n",
    "GROUP BY ORIGIN_COUNTRY_NAME\n",
    "HAVING num_flights > 500\n",
    "ORDER BY num_flights DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "spark.sql(query).show()\n",
    "\n",
    "# More complex query with multiple aggregations\n",
    "query_advanced = \"\"\"\n",
    "SELECT ORIGIN_COUNTRY_NAME, SUM(count) AS total_passengers, AVG(count) AS avg_flights\n",
    "FROM temp_flights\n",
    "GROUP BY ORIGIN_COUNTRY_NAME\n",
    "ORDER BY total_passengers DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "spark.sql(query_advanced).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7664948f",
   "metadata": {},
   "source": [
    "**2. Global Temporary Views:**\n",
    "Global temporary views are accessible across multiple sessions using the `global_temp` database.\n",
    "\n",
    "*Example 3: Creating and querying a global temporary view*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a global temporary view\n",
    "df.createOrReplaceGlobalTempView(\"global_flights\")\n",
    "\n",
    "# Query the global view\n",
    "query = \"SELECT * FROM global_temp.global_flights WHERE count > 500\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c9d9cf",
   "metadata": {},
   "source": [
    "**3. Managed Tables:**\n",
    "Managed tables are stored in Spark's warehouse directory and managed by Spark.\n",
    "\n",
    "*Example 4: Creating a managed table and inserting data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS managed_table (DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\")\n",
    "spark.sql(\"INSERT INTO managed_table SELECT * FROM temp_flights\")\n",
    "spark.sql(\"SELECT * FROM managed_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f39820",
   "metadata": {},
   "source": [
    "**4. External Tables:**\n",
    "External tables reference data stored outside Spark's warehouse, such as in a data lake.\n",
    "\n",
    "*Example 5: Creating an external table*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81066727",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE TABLE external_table USING PARQUET LOCATION 'dbfs:/mnt/data/data/flight-data/parquet'\")\n",
    "spark.sql(\"SELECT * FROM external_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecd5feb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Performance Optimization with Catalyst Optimizer\n",
    "\n",
    "The Catalyst Optimizer is a key component of Spark SQL, designed to enhance query performance through logical and physical plan optimization.\n",
    "\n",
    "**Key Techniques:**\n",
    "- **Predicate Pushdown:** Filters are applied early to reduce data scanning.\n",
    "- **Column Pruning:** Reads only required columns from the data source.\n",
    "- **Join Optimization:** Reorders joins for optimal execution.\n",
    "- **Query Caching:** Uses in-memory storage for frequently accessed data.\n",
    "\n",
    "*Example 6: Using query caching for performance optimization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01430af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache query result\n",
    "cached_result = spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, SUM(count) AS total_flights\n",
    "FROM flight_data\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\")\n",
    "cached_result.cache()\n",
    "cached_result.count()\n",
    "cached_result.show()\n",
    "\n",
    "# Explain the query plan\n",
    "cached_result.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a33d99",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Using Databricks SQL for Queries and Visualization\n",
    "\n",
    "Databricks SQL provides a user-friendly interface for running SQL queries and creating visualizations.\n",
    "\n",
    "**Steps to Use Databricks SQL:**\n",
    "1. Navigate to the SQL editor in Databricks.\n",
    "2. Select or create a SQL warehouse.\n",
    "3. Write and execute SQL queries.\n",
    "4. Create dashboards and visualizations.\n",
    "\n",
    "*Example 7: Running a SQL query in Databricks SQL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, SUM(count) AS total_flights\n",
    "FROM flight_data\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "ORDER BY total_flights DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26313e96",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exhaustive Code Examples\n",
    "\n",
    "*Example 8: Aggregation with multiple conditions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ed610",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ORIGIN_COUNTRY_NAME, COUNT(*) AS num_flights, SUM(count) AS total_passengers\n",
    "FROM flight_data\n",
    "GROUP BY ORIGIN_COUNTRY_NAME\n",
    "HAVING num_flights > 500\n",
    "ORDER BY total_passengers DESC\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38099d8",
   "metadata": {},
   "source": [
    "*Example 9: Complex joins and filtering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b44bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2010 = spark.read.json(\"dbfs:/mnt/data/data/flight-data/json/2010-summary.json\")\n",
    "flights_2010.createOrReplaceTempView(\"flights_2010\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT a.DEST_COUNTRY_NAME, a.count AS count_2015, b.count AS count_2010\n",
    "FROM flight_data a\n",
    "INNER JOIN flights_2010 b\n",
    "ON a.DEST_COUNTRY_NAME = b.DEST_COUNTRY_NAME\n",
    "WHERE a.count > 500 AND b.count > 500\n",
    "ORDER BY a.count DESC\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f95dc8",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
